{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Twitter Sentiment Analysis\n",
    "===============\n",
    "This project is about analyzing tweets. We have a dataset with 1.6 million tweets at our disposal and they are labelled 0 (negative) or 4 (positive). <br> Our purpose is to exploit it in order to develop an algorithm for identifying the **sentiment polarity** in a tweet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing all the needed packages.\n",
    "\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import spacy\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "import seaborn as sn\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data cleaning and preparation\n",
    "Our first step will be to visualize our dataset in order to check whether it is \"ready to use\" or it needs to be adjusted before proceeding to build the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810369</td>\n",
       "      <td>Mon Apr 06 22:19:45 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>_TheSpecialOne_</td>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810672</td>\n",
       "      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>scotthamilton</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810917</td>\n",
       "      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>mattycus</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811184</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>ElleCTF</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811193</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Karoli</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0           1                             2         3                4  \\\n",
       "0  0  1467810369  Mon Apr 06 22:19:45 PDT 2009  NO_QUERY  _TheSpecialOne_   \n",
       "1  0  1467810672  Mon Apr 06 22:19:49 PDT 2009  NO_QUERY    scotthamilton   \n",
       "2  0  1467810917  Mon Apr 06 22:19:53 PDT 2009  NO_QUERY         mattycus   \n",
       "3  0  1467811184  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY          ElleCTF   \n",
       "4  0  1467811193  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY           Karoli   \n",
       "\n",
       "                                                   5  \n",
       "0  @switchfoot http://twitpic.com/2y1zl - Awww, t...  \n",
       "1  is upset that he can't update his Facebook by ...  \n",
       "2  @Kenichan I dived many times for the ball. Man...  \n",
       "3    my whole body feels itchy and like its on fire   \n",
       "4  @nationwideclass no, it's not behaving at all....  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing the dataset and giving it a look.\n",
    "\n",
    "df = pd.read_csv(\"training.1600000.processed.noemoticon.csv\", engine = \"python\", header = None)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sentiment                                              Tweet\n",
       "0          0  @switchfoot http://twitpic.com/2y1zl - Awww, t...\n",
       "1          0  is upset that he can't update his Facebook by ...\n",
       "2          0  @Kenichan I dived many times for the ball. Man...\n",
       "3          0    my whole body feels itchy and like its on fire \n",
       "4          0  @nationwideclass no, it's not behaving at all...."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Adjusting the dataset according to our needs.\n",
    "\n",
    "df = df.iloc[:, [0,5]]\n",
    "df.columns = [\"Sentiment\", \"Tweet\"]\n",
    "df[\"Sentiment\"] = pd.to_numeric(df[\"Sentiment\"])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing some noise.\n",
    "\n",
    "def cleaner(tweet):\n",
    "    tweet = BeautifulSoup(tweet).get_text() # HTML tags\n",
    "    tweet = re.sub(r'@\\S+', '', tweet) # Mentions\n",
    "    tweet = re.sub(r'http\\S+', '', tweet) # Links\n",
    "    for i in tweet.split():\n",
    "        if i==\"rt\":\n",
    "            tweet = re.sub(i, \"\", tweet) # Retweets\n",
    "    tweet = re.sub(\"#\", \"\", tweet) # Hashes\n",
    "    tweet = tweet.lower() # Converting to lower case\n",
    "    tweet = tweet.lstrip() # Initial and final spaces\n",
    "    tweet = re.sub(\"\\s\\s+\", \" \", tweet) # Double spaces\n",
    "    return tweet\n",
    "df[\"Tweet\"] = df[\"Tweet\"].apply(lambda x: cleaner(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1600000 rows and 2 columns.\n",
      "Missing values found: 0. Every field is properly filled.\n"
     ]
    }
   ],
   "source": [
    "# Visualizing the shape of the dataset and checking if all the fields are properly filled.\n",
    "\n",
    "print(\"There are \" + str(df.shape[0]) + \" rows and \" + str(df.shape[1]) + \" columns.\")\n",
    "nancount = df.isnull().sum().sum()\n",
    "if nancount==0:\n",
    "    print(\"Missing values found: 0. Every field is properly filled.\")\n",
    "else:\n",
    "    print(\"Missing values found: \" + str(nancount) + \". Deal with them before moving on.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Showing the percentage distribution of the labels.\n",
    "\n",
    "labels = [\"Negative (0)\", \"Positive (4)\"]\n",
    "negcount=0\n",
    "poscount=0\n",
    "for i in df.Sentiment:\n",
    "    if i==0:\n",
    "        negcount+=1\n",
    "    elif i==4:\n",
    "        poscount+=1\n",
    "sizes = [poscount, negcount]\n",
    "colors = [\"red\", \"green\"]\n",
    "plt.pie(sizes, labels=labels, colors=colors, autopct='%1.1f%%', startangle=270)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Exploratory Data Analysis\n",
    "The second step will be to perform an exploratory data analysis: we will analyze every single tweet by performing some NLP techniques such as PoS, NER etc.\n",
    "\n",
    "NOTE: performing this kind of analysis on the whole dataframe would require significant amount of time. Therefore, for simplicity and given that we are not going to train the algorithms with the features from the analysis, we will analyze only the first 100 tweets (to analyze the whole dataset, it is enough to replace \"0:100\" with \"100\" as the first argument of the function \".iloc\" when creating the dataframe called \"EDA\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the SpaCy object and creating another dataframe for our analysis.\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "EDA = df.iloc[0:100, 1]\n",
    "EDA = EDA.to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenization: breaking the stream of characters into words (tokens).\n",
    "\n",
    "def tokenization(tweet):\n",
    "    tweet = nlp(tweet)\n",
    "    tok = []\n",
    "    for i in tweet:\n",
    "        tok.append(i.text)\n",
    "    return tok\n",
    "EDA[\"Tokenization\"] = EDA[\"Tweet\"].apply(lambda x: tokenization(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sentence Size: adding the length of the sentence (number of tokens).\n",
    "\n",
    "def length(x):\n",
    "    return len(x)\n",
    "EDA[\"Sentence Size\"] = EDA[\"Tokenization\"].apply(lambda x: length(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stopwords: List of most common words of a language that are often useful to filter out.\n",
    "\n",
    "def stopwords(tweet):\n",
    "    stops = []\n",
    "    for i in tweet:\n",
    "        if nlp.vocab[i].is_stop:\n",
    "            stops.append(i)\n",
    "    return stops\n",
    "EDA[\"Stopwords\"] = EDA[\"Tokenization\"].apply(lambda x: stopwords(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PoS: marking up a word in a text (corpus) as corresponding to a particular part of speech, based on both its\n",
    "# definition and its context.\n",
    "\n",
    "def PoS(tweet):\n",
    "    tweet = nlp(tweet)\n",
    "    pos = []\n",
    "    for i in tweet:\n",
    "        pos.append([i.text, i.pos_])\n",
    "    return pos\n",
    "EDA[\"PoS\"] = EDA[\"Tweet\"].apply(lambda x: PoS(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependency parsing: assigning a syntactic structure to the text.\n",
    "\n",
    "def dependencyparsing(tweet):\n",
    "    tweet = nlp(tweet)\n",
    "    dep = []\n",
    "    for i in tweet:\n",
    "        dep.append([i.text, i.dep_])\n",
    "    return dep\n",
    "EDA[\"Dependency Parsing\"] = EDA[\"Tweet\"].apply(lambda x: dependencyparsing(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NER (Named Entity Recognition): identifying token spans fitting a predetermined set of named entities.\n",
    "\n",
    "def NER(tweet):\n",
    "    tweet = nlp(tweet)\n",
    "    ner = []\n",
    "    if tweet.ents:\n",
    "        for i in tweet.ents:\n",
    "            ner.append([i.text, i.label_])\n",
    "    else:\n",
    "        ner.append(\"No named entities found.\")\n",
    "    return ner\n",
    "EDA[\"NER\"] = EDA[\"Tweet\"].apply(lambda x: NER(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Noun Chunks: Flat phrases that have a noun as their head.\n",
    "\n",
    "def nounchunks(tweet):\n",
    "    tweet = nlp(tweet)\n",
    "    chunks = []\n",
    "    for i in tweet.noun_chunks:\n",
    "        chunks.append(i.text)\n",
    "    return chunks\n",
    "EDA[\"Noun Chunks\"] = EDA[\"Tweet\"].apply(lambda x: nounchunks(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Tokenization</th>\n",
       "      <th>Sentence Size</th>\n",
       "      <th>Stopwords</th>\n",
       "      <th>PoS</th>\n",
       "      <th>Dependency Parsing</th>\n",
       "      <th>NER</th>\n",
       "      <th>Noun Chunks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>- awww, that's a bummer. you shoulda got david...</td>\n",
       "      <td>[-, awww, ,, that, 's, a, bummer, ., you, shou...</td>\n",
       "      <td>22</td>\n",
       "      <td>[that, 's, a, you, of, third, to, do, it]</td>\n",
       "      <td>[[-, PUNCT], [awww, PROPN], [,, PUNCT], [that,...</td>\n",
       "      <td>[[-, punct], [awww, advmod], [,, punct], [that...</td>\n",
       "      <td>[[shoulda, PERSON], [david carr, PERSON], [thi...</td>\n",
       "      <td>[a bummer, you, shoulda, david carr, third day...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>is upset that he can't update his facebook by ...</td>\n",
       "      <td>[is, upset, that, he, ca, n't, update, his, fa...</td>\n",
       "      <td>25</td>\n",
       "      <td>[is, that, he, ca, n't, his, by, it, and, migh...</td>\n",
       "      <td>[[is, AUX], [upset, ADJ], [that, SCONJ], [he, ...</td>\n",
       "      <td>[[is, ROOT], [upset, acomp], [that, mark], [he...</td>\n",
       "      <td>[[today, DATE]]</td>\n",
       "      <td>[he, his facebook, it, a result school]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i dived many times for the ball. managed to sa...</td>\n",
       "      <td>[i, dived, many, times, for, the, ball, ., man...</td>\n",
       "      <td>19</td>\n",
       "      <td>[i, many, for, the, to, the, go, out, of]</td>\n",
       "      <td>[[i, PRON], [dived, VERB], [many, ADJ], [times...</td>\n",
       "      <td>[[i, nsubj], [dived, ROOT], [many, amod], [tim...</td>\n",
       "      <td>[[50%, PERCENT]]</td>\n",
       "      <td>[i, the ball, 50%, the rest, bounds]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "      <td>[my, whole, body, feels, itchy, and, like, its...</td>\n",
       "      <td>10</td>\n",
       "      <td>[my, whole, and, its, on]</td>\n",
       "      <td>[[my, DET], [whole, ADJ], [body, NOUN], [feels...</td>\n",
       "      <td>[[my, poss], [whole, amod], [body, nsubj], [fe...</td>\n",
       "      <td>[No named entities found.]</td>\n",
       "      <td>[my whole body, fire]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>no, it's not behaving at all. i'm mad. why am ...</td>\n",
       "      <td>[no, ,, it, 's, not, behaving, at, all, ., i, ...</td>\n",
       "      <td>28</td>\n",
       "      <td>[no, it, 's, not, at, all, i, 'm, why, am, i, ...</td>\n",
       "      <td>[[no, INTJ], [,, PUNCT], [it, PRON], ['s, AUX]...</td>\n",
       "      <td>[[no, intj], [,, punct], [it, nsubj], ['s, aux...</td>\n",
       "      <td>[No named entities found.]</td>\n",
       "      <td>[it, i, i, i, you]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Tweet  \\\n",
       "0  - awww, that's a bummer. you shoulda got david...   \n",
       "1  is upset that he can't update his facebook by ...   \n",
       "2  i dived many times for the ball. managed to sa...   \n",
       "3    my whole body feels itchy and like its on fire    \n",
       "4  no, it's not behaving at all. i'm mad. why am ...   \n",
       "\n",
       "                                        Tokenization  Sentence Size  \\\n",
       "0  [-, awww, ,, that, 's, a, bummer, ., you, shou...             22   \n",
       "1  [is, upset, that, he, ca, n't, update, his, fa...             25   \n",
       "2  [i, dived, many, times, for, the, ball, ., man...             19   \n",
       "3  [my, whole, body, feels, itchy, and, like, its...             10   \n",
       "4  [no, ,, it, 's, not, behaving, at, all, ., i, ...             28   \n",
       "\n",
       "                                           Stopwords  \\\n",
       "0          [that, 's, a, you, of, third, to, do, it]   \n",
       "1  [is, that, he, ca, n't, his, by, it, and, migh...   \n",
       "2          [i, many, for, the, to, the, go, out, of]   \n",
       "3                          [my, whole, and, its, on]   \n",
       "4  [no, it, 's, not, at, all, i, 'm, why, am, i, ...   \n",
       "\n",
       "                                                 PoS  \\\n",
       "0  [[-, PUNCT], [awww, PROPN], [,, PUNCT], [that,...   \n",
       "1  [[is, AUX], [upset, ADJ], [that, SCONJ], [he, ...   \n",
       "2  [[i, PRON], [dived, VERB], [many, ADJ], [times...   \n",
       "3  [[my, DET], [whole, ADJ], [body, NOUN], [feels...   \n",
       "4  [[no, INTJ], [,, PUNCT], [it, PRON], ['s, AUX]...   \n",
       "\n",
       "                                  Dependency Parsing  \\\n",
       "0  [[-, punct], [awww, advmod], [,, punct], [that...   \n",
       "1  [[is, ROOT], [upset, acomp], [that, mark], [he...   \n",
       "2  [[i, nsubj], [dived, ROOT], [many, amod], [tim...   \n",
       "3  [[my, poss], [whole, amod], [body, nsubj], [fe...   \n",
       "4  [[no, intj], [,, punct], [it, nsubj], ['s, aux...   \n",
       "\n",
       "                                                 NER  \\\n",
       "0  [[shoulda, PERSON], [david carr, PERSON], [thi...   \n",
       "1                                    [[today, DATE]]   \n",
       "2                                   [[50%, PERCENT]]   \n",
       "3                         [No named entities found.]   \n",
       "4                         [No named entities found.]   \n",
       "\n",
       "                                         Noun Chunks  \n",
       "0  [a bummer, you, shoulda, david carr, third day...  \n",
       "1            [he, his facebook, it, a result school]  \n",
       "2               [i, the ball, 50%, the rest, bounds]  \n",
       "3                              [my whole body, fire]  \n",
       "4                                 [it, i, i, i, you]  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# At the end, our dataframe built for Exploratory Data Analysis looks like this:\n",
    "\n",
    "EDA.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i\tIs this a stopword? True\tPRON\tnsubj\n",
      "dived\tIs this a stopword? False\tVERB\tROOT\n",
      "many\tIs this a stopword? True\tADJ\tamod\n",
      "times\tIs this a stopword? False\tNOUN\tnpadvmod\n",
      "for\tIs this a stopword? True\tADP\tprep\n",
      "the\tIs this a stopword? True\tDET\tdet\n",
      "ball\tIs this a stopword? False\tNOUN\tpobj\n",
      ".\tIs this a stopword? False\tPUNCT\tpunct\n",
      "managed\tIs this a stopword? False\tVERB\tROOT\n",
      "to\tIs this a stopword? True\tPART\taux\n",
      "save\tIs this a stopword? False\tVERB\txcomp\n",
      "50\tIs this a stopword? False\tNUM\tnummod\n",
      "%\tIs this a stopword? False\tNOUN\tdobj\n",
      "the\tIs this a stopword? True\tDET\tdet\n",
      "rest\tIs this a stopword? False\tNOUN\tnsubj\n",
      "go\tIs this a stopword? True\tVERB\tROOT\n",
      "out\tIs this a stopword? True\tSCONJ\tprep\n",
      "of\tIs this a stopword? True\tADP\tprep\n",
      "bounds\tIs this a stopword? False\tNOUN\tpobj\n"
     ]
    }
   ],
   "source": [
    "# To visualize the analysis related to a specific tweet it is enough to retrieve the row of the tweet of interest\n",
    "# in the EDA dataframe.\n",
    "# Alternatively, for a word-by-word analysis, you can change the number inside the square brackets in the following\n",
    "# code and then execute it.\n",
    "\n",
    "for i in nlp(EDA.Tweet[2]):\n",
    "    print(i.text, \"Is this a stopword? \" + str(i.is_stop), i.pos_, i.dep_, sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Machine Learning approach\n",
    "\n",
    "We are now in the critical part: choosing the best Machine Learning algorithm for predicting the sentiment polarity of a tweet. <br> The first thing to know is that raw text cannot be passed into a ML algorithm, therefore, we will extract features from our text by applying the **vectorization** (that is, extracting features from the raw text in order to pass numerical features to the machine learning algorithm). <br> After that, it will be possible to train, test and compare all of the different algorithms.\n",
    "\n",
    "The vectorization functions that we are going to use are Count Vectorizer and TF-IDF Vectorizer. <br>\n",
    "The machine learning algorithms that we are going to train and test are: Support Vector Machine, Multinomial Naive Bayes and Multinomial Logistic Regression.\n",
    "\n",
    "We will try every possible combination and in the end we will see which one performed better by looking at the **metrics**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's first modify our dataset one last time: lemmatization. It converts each token to its standard form.\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "def lemmatization(tweet):\n",
    "    tweet = \" \".join([lemmatizer.lemmatize(word) for word in tweet.split()])\n",
    "    return tweet\n",
    "df[\"Tweet\"] = df[\"Tweet\"].apply(lambda x: lemmatization(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating another dataframe equal to the original one, but shuffled. Then dividing data into 80% training and\n",
    "# 20% test.\n",
    "\n",
    "ml_df = shuffle(df, random_state=0)\n",
    "X = ml_df[\"Tweet\"]\n",
    "y = ml_df[\"Sentiment\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the pipelines (Vectorization -> Training).\n",
    "\n",
    "cv_svc = Pipeline([('cv', CountVectorizer()),\n",
    "                     ('clf', LinearSVC())])\n",
    "cv_mnb = Pipeline([('cv', CountVectorizer()),\n",
    "                     ('clf', MultinomialNB())])\n",
    "cv_lr = Pipeline([('cv', CountVectorizer()),\n",
    "                     ('clf', LogisticRegression())])\n",
    "tfidf_svc = Pipeline([('tfidf', TfidfVectorizer()),\n",
    "                     ('clf', LinearSVC())])\n",
    "tfidf_mnb = Pipeline([('tfidf', TfidfVectorizer()),\n",
    "                     ('clf', MultinomialNB())])\n",
    "tfidf_lr = Pipeline([('tfidf', TfidfVectorizer()),\n",
    "                     ('clf', LogisticRegression())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nevrocerasani/opt/anaconda3/envs/text_mining/lib/python3.7/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/nevrocerasani/opt/anaconda3/envs/text_mining/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Users/nevrocerasani/opt/anaconda3/envs/text_mining/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('tfidf',\n",
       "                 TfidfVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.float64'>,\n",
       "                                 encoding='utf-8', input='content',\n",
       "                                 lowercase=True, max_df=1.0, max_features=None,\n",
       "                                 min_df=1, ngram_range=(1, 1), norm='l2',\n",
       "                                 preprocessor=None, smooth_idf=True,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 sublinear_tf=False,\n",
       "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                 tokenizer=None, use_idf=True,\n",
       "                                 vocabulary=None)),\n",
       "                ('clf',\n",
       "                 LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
       "                                    fit_intercept=True, intercept_scaling=1,\n",
       "                                    l1_ratio=None, max_iter=100,\n",
       "                                    multi_class='auto', n_jobs=None,\n",
       "                                    penalty='l2', random_state=None,\n",
       "                                    solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                                    warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training the algorithms.\n",
    "\n",
    "cv_svc.fit(X_train, y_train)\n",
    "cv_mnb.fit(X_train, y_train)\n",
    "cv_lr.fit(X_train, y_train)\n",
    "tfidf_svc.fit(X_train, y_train)\n",
    "tfidf_mnb.fit(X_train, y_train)\n",
    "tfidf_lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing the algorithms.\n",
    "\n",
    "test_cv_svc = cv_svc.predict(X_test)\n",
    "test_cv_mnb = cv_mnb.predict(X_test)\n",
    "test_cv_lr = cv_lr.predict(X_test)\n",
    "test_tfidf_svc = tfidf_svc.predict(X_test)\n",
    "test_tfidf_mnb = tfidf_mnb.predict(X_test)\n",
    "test_tfidf_lr = tfidf_lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Incorporating their accuracies inside the variables for simplicity.\n",
    "\n",
    "acc_cv_svc = metrics.accuracy_score(y_test, test_cv_svc)\n",
    "acc_cv_mnb = metrics.accuracy_score(y_test, test_cv_mnb)\n",
    "acc_cv_lr = metrics.accuracy_score(y_test, test_cv_lr)\n",
    "acc_tfidf_svc = metrics.accuracy_score(y_test, test_tfidf_svc)\n",
    "acc_tfidf_mnb = metrics.accuracy_score(y_test, test_tfidf_mnb)\n",
    "acc_tfidf_lr = metrics.accuracy_score(y_test, test_tfidf_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a dataframe with all the accuracies to see which model performed better.\n",
    "\n",
    "accuracy = [[\"Count Vectorizer\", \"Support Vector Machine\", acc_cv_svc], [\"Count Vectorizer\", \"Multinomial Naive Bayes\", acc_cv_mnb], [\"Count Vectorizer\", \"Multinomial Logistic Regression\", acc_cv_lr],\n",
    "           [\"TF-IDF\", \"Support Vector Machine\", acc_tfidf_svc], [\"TF-IDF\", \"Multinomial Naive Bayes\", acc_tfidf_mnb], [\"TF-IDF\", \"Multinomial Logistic Regression\", acc_tfidf_lr]]\n",
    "accuracy_df = pd.DataFrame(accuracy, columns = [\"Vectorization\", \"Algorithm\", \"Accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Vectorization</th>\n",
       "      <th>Algorithm</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Count Vectorizer</td>\n",
       "      <td>Support Vector Machine</td>\n",
       "      <td>0.788112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Count Vectorizer</td>\n",
       "      <td>Multinomial Naive Bayes</td>\n",
       "      <td>0.779750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Count Vectorizer</td>\n",
       "      <td>Multinomial Logistic Regression</td>\n",
       "      <td>0.795053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TF-IDF</td>\n",
       "      <td>Support Vector Machine</td>\n",
       "      <td>0.791978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TF-IDF</td>\n",
       "      <td>Multinomial Naive Bayes</td>\n",
       "      <td>0.773403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>TF-IDF</td>\n",
       "      <td>Multinomial Logistic Regression</td>\n",
       "      <td>0.796681</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Vectorization                        Algorithm  Accuracy\n",
       "0  Count Vectorizer           Support Vector Machine  0.788112\n",
       "1  Count Vectorizer          Multinomial Naive Bayes  0.779750\n",
       "2  Count Vectorizer  Multinomial Logistic Regression  0.795053\n",
       "3            TF-IDF           Support Vector Machine  0.791978\n",
       "4            TF-IDF          Multinomial Naive Bayes  0.773403\n",
       "5            TF-IDF  Multinomial Logistic Regression  0.796681"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report: \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.78      0.79    159897\n",
      "           4       0.79      0.81      0.80    160103\n",
      "\n",
      "    accuracy                           0.80    320000\n",
      "   macro avg       0.80      0.80      0.80    320000\n",
      "weighted avg       0.80      0.80      0.80    320000\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# It seems that the best performing algorithm is the Multinomial Logistic Regression, with the text vectorized by\n",
    "# the TF-IDF technique: we reached an accuracy of 80%!\n",
    "# Let's investigate it in further details by looking at the classification report and the confusion matrix.\n",
    "\n",
    "print(\"Classification report: \\n\")\n",
    "print(metrics.classification_report(y_test, test_tfidf_lr))\n",
    "cm = metrics.confusion_matrix(y_test, test_tfidf_lr)\n",
    "plt.figure(figsize=(5,5))\n",
    "sn.heatmap(cm, annot=True, fmt=\"d\")\n",
    "plt.title(\"Confusion matrix \\n \\n\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the end of our sentiment analysis, we can conclude that all of the compared algorithms did a great job. They all reached more or less the same accuracy with minimum deviations, but the best performing one was the **Multinomial Logistic Regression** combined with the **TF-IDF** vectorization technique.\n",
    "Our choice is justified by its 80% accuracy: in plain words it means that our algorithm is able to tell a positive tweet from a negative one 80 times out of 100.\n",
    "More in detail: the total number of correctly classified tweets is 254.938 (125.385 + 129.553), while the total number of wrongly classified tweets is 65.062 (30.550 + 34.512)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Neural Network Approach\n",
    "\n",
    "We now try to compare the previous Machine Learning approaches with a neural network approach, specifically with LSTM, a Recurrent Neural Network, to see if we can get a better accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Word embedding before fitting the neural network\n",
    "\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(ml_df[\"Tweet\"])\n",
    "max_length = max([len(s.split()) for s in ml_df[\"Tweet\"]])\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "X_train_tokens = tokenizer.texts_to_sequences(X_train[:20000])\n",
    "X_test_tokens = tokenizer.texts_to_sequences(X_test[:20000])\n",
    "X_train_pad = pad_sequences(X_train_tokens, maxlen=max_length, padding = \"post\")\n",
    "X_test_pad = pad_sequences(X_test_tokens, maxlen=max_length, padding = \"post\")\n",
    "scaler_object = MinMaxScaler()\n",
    "scaler_object.fit(X_train_pad)\n",
    "scaled_X_train = scaler_object.transform(X_train_pad)\n",
    "scaled_X_test = scaler_object.transform(X_test_pad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nevrocerasani/opt/anaconda3/envs/text_mining/lib/python3.7/site-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "20000/20000 [==============================] - 261s 13ms/step - loss: -18.8603 - accuracy: 0.0000e+00\n",
      "Epoch 2/3\n",
      "20000/20000 [==============================] - 258s 13ms/step - loss: -42.2444 - accuracy: 0.0000e+00\n",
      "Epoch 3/3\n",
      "20000/20000 [==============================] - 258s 13ms/step - loss: -64.8665 - accuracy: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1a52206c50>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating and fitting the neural network\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, 100, input_length=max_length))\n",
    "model.add(LSTM(100, input_shape=(None,1), activation = \"relu\", return_sequences = True))\n",
    "model.add(LSTM(100, return_sequences = False))\n",
    "model.add(Dense(1, activation=\"sigmoid\"))\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model.fit(scaled_X_train, y_train[:20000], batch_size=64, epochs=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that there is something wrong in our model, probably in the parameters or in the way we inputted the data, given that an accuracy of 0% and a loss function that progressively decreases is very unlikely to happen.\n",
    "Therefore, for our predictions we will rely on our machine learning approaches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
